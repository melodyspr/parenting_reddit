{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do mothers and fathers talk about parenting to different audiences? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LDA Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ea-LeIgCxPmp"
   },
   "outputs": [],
   "source": [
    "## Load needed modules\n",
    "# Import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import gensim\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # To ignore all warnings that arise here to enhance clarity\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array\n",
    "%config Completer.use_jedi = False\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import logging\n",
    "logging.basicConfig(filename='gensim.log',\n",
    "                    format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary functions to calculate coherence values and run the topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coherence values LdaModel\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state = 100, chunksize = 10000, passes = 20, iterations = 100)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coherence values LdaMallet\n",
    "def mallet_compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=dictionary, random_seed=100)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with nouns and verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset with nouns and verbs\n",
    "preprocessed = pd.read_pickle('tokenized_nouns_verbs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "add_stop_words = [\"time\", \"hair\", \"day\", \"day\", \"month\", \"week\", \"hour\", \"year\", \"minute\", \"idea\", \"adult\", \"age\", \"comment\", \"people\", \"person\", \"man\", \"sure\"]\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "#remove stopwords from tokenized dataset\n",
    "preprocessed['body'] = preprocessed['body'].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove empty comments\n",
    "preprocessed = preprocessed[preprocessed.astype(str)['body'] != \"[]\"]\n",
    "#Reset the indexes\n",
    "preprocessed = preprocessed.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to array\n",
    "docs_old = list(preprocessed['body'].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Biagram & Trigram Models \n",
    "from gensim.models import Phrases\n",
    "# Add bigrams and trigrams to docs,minimum count 20 means only that appear 20 times or more.\n",
    "bigram = Phrases(docs_old, min_count=20)\n",
    "\n",
    "for idx in range(len(docs_old)):\n",
    "    for token in bigram[docs_old[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs_old[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs_old.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "#Gensim filter_extremes\n",
    "#Filter out tokens that appear in less than 15 documents (absolute number) or more than 0.5 documents (fraction of total corpus size, not absolute number). \n",
    "dictionary.filter_extremes(no_below=5, no_above=0.20)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))\n",
    "print(corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_comments = 0\n",
    "for comment in corpus:\n",
    "    if len(comment) == 0:\n",
    "        empty_comments += 1\n",
    "print(empty_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove empty comments\n",
    "corpus = [x for x in corpus if x != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=corpus, texts=docs, start=2, limit=50, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "import matplotlib.pyplot as plt\n",
    "limit=50; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "#Coherence values were lower than the model with only nouns so I decides to keep the latter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with only nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset with only nouns\n",
    "preprocessed_nouns = pd.read_pickle('tokenized_nouns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "add_stop_words = [\"time\", \"hair\", \"day\", \"month\", \"week\", \"hour\", \"year\", \"minute\", \"idea\", \"adult\", \"age\", \"comment\", \"people\", \"person\", \"man\", \"sure\"]\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "#remove stopwords from tokenized dataset\n",
    "preprocessed_nouns['body'] = preprocessed_nouns['body'].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove empty comments\n",
    "preprocessed_nouns = preprocessed_nouns[preprocessed_nouns.astype(str)['body'] != \"[]\"]\n",
    "#Reset the indexes\n",
    "preprocessed_nouns = preprocessed_nouns.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to array\n",
    "docs_old_nouns = list(preprocessed_nouns['body'].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Biagram & Trigram Models \n",
    "from gensim.models import Phrases\n",
    "# Add bigrams and trigrams to docs,minimum count 20 means only that appear 20 times or more.\n",
    "bigram = Phrases(docs_old_nouns, min_count=20)\n",
    "\n",
    "for idx in range(len(docs_old_nouns)):\n",
    "    for token in bigram[docs_old_nouns[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs_old_nouns[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_nouns = docs_old_nouns.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary representation of the documents. It gives an integer to each word\n",
    "dictionary_nouns = Dictionary(docs_nouns)\n",
    "#Gensim filter_extremes\n",
    "#Filter out tokens that appear in less than 15 documents (absolute number) or more than 0.5 documents (fraction of total corpus size, not absolute number). \n",
    "dictionary_nouns.filter_extremes(no_below=5, no_above=0.20)\n",
    "corpus_nouns = [dictionary_nouns.doc2bow(doc) for doc in docs_nouns]\n",
    "print('Number of unique tokens: %d' % len(dictionary_nouns))\n",
    "print('Number of documents: %d' % len(corpus_nouns))\n",
    "print(corpus_nouns[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_comments = 0\n",
    "for comment in corpus_nouns:\n",
    "    if len(comment) == 0:\n",
    "        empty_comments += 1\n",
    "print(empty_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove empty comments\n",
    "corpus_nouns = [x for x in corpus_nouns if x != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying LDAmallet\n",
    "mallet_path = '/Users/melodys/Downloads/mallet-2.0.8/bin/mallet' # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus_nouns, num_topics=10, id2word=dictionary_nouns)\n",
    "mallet_model_list, mallet_coherence_values = mallet_compute_coherence_values(dictionary=dictionary_nouns, corpus=corpus_nouns, texts=docs_nouns, start=2, limit=50, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "limit=50; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, mallet_coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Topics\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus_nouns, num_topics=13, id2word=dictionary_nouns, random_seed=100)\n",
    "ldamallet.print_topics()\n",
    "#The resulting models had higher coherence scores but were less interpretable than Gensim LDAModel so I decided to continue with the latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list_nouns, coherence_values_nouns = compute_coherence_values(dictionary=dictionary_nouns, corpus=corpus_nouns, texts=docs_nouns, start=2, limit=50, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "limit=50; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values_nouns)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "fig.savefig('coherence score graph.jpeg', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#once we have chosen the number of topics we want, then we calculate the coherence scores for different values of the hyperparameters alpha and beta\n",
    "def compute_coherence_values_a_b(dictionary, corpus, texts):\n",
    "    # Alpha parameter\n",
    "    alpha = list(np.arange(0.01, 0.62, 0.3))\n",
    "    alpha.append('symmetric')\n",
    "    alpha.append('asymmetric')\n",
    "    # Beta parameter\n",
    "    beta = list(np.arange(0.01, 0.62, 0.3))\n",
    "    beta.append('symmetric')\n",
    " \n",
    "    model_results = {'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "    for a in alpha:\n",
    "        # iterare through beta values\n",
    "        for b in beta:    \n",
    "            lda_model = LdaModel(corpus = corpus,\n",
    "                                id2word = dictionary,\n",
    "                                num_topics = 12, \n",
    "                                random_state = 100,\n",
    "                                chunksize = 1000,\n",
    "                                passes = 20,\n",
    "                                iterations = 100,\n",
    "                                alpha = a,\n",
    "                                eta = b)\n",
    "            coherencemodel = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "            model_results['Topics'].append(12)\n",
    "            model_results['Alpha'].append(a)\n",
    "            model_results['Beta'].append(b)\n",
    "            model_results['Coherence'].append(coherencemodel.get_coherence())\n",
    "\n",
    "\n",
    "    return pd.DataFrame(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_beta_12 = compute_coherence_values_a_b(dictionary=dictionary_nouns, corpus=corpus_nouns, texts=docs_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_beta_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score using c_v\n",
    "coherence_model_lda_12 = CoherenceModel(model=lda_model_12, texts=docs_nouns, dictionary=dictionary_nouns, coherence='c_v')\n",
    "coherence_lda_12 = coherence_model_lda_12.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters of the LDA model with 12 topics\n",
    "lda_model_12 = LdaModel(corpus=corpus_nouns,\n",
    "                        id2word=dictionary_nouns,\n",
    "                        num_topics = 12, \n",
    "                        random_state = 100,\n",
    "                        chunksize = 5000,\n",
    "                        passes = 40,\n",
    "                        iterations = 1000,\n",
    "                        alpha = 0.01,\n",
    "                        eta = 0.61)\n",
    "# Print the Keyword in the 12 topics\n",
    "lda_model_12.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise the topic model\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda_model_12, corpus_nouns, dictionary=lda_model_12.id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the file that we will apply to give a score to comments\n",
    "data_clean = pd.read_pickle('NEW_data_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the dataframe\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, get a list of posts, one by one\n",
    "CompletePosts = list(data_clean[\"lemmatized\"])\n",
    "\n",
    "#create a bag of words for each of the comments\n",
    "#for this, we will use doc2bow --> document to bag of words       \n",
    "new_doc2bow = [dictionary_nouns.doc2bow(post) for post in CompletePosts]\n",
    "#The vector will contain all the weights for each of the 14 topics\n",
    "vector = lda_model_12.get_document_topics(new_doc2bow)\n",
    "\n",
    "#create a list of dictioaries for scores relating to optimum LDA\n",
    "newdictlist = []\n",
    "for i in range(0, len(vector)):\n",
    "    newdictlist.append(dict(vector[i]))\n",
    "\n",
    "#create a pandas dataframe\n",
    "topic_bow = pd.DataFrame(newdictlist)\n",
    "topic_bow = topic_bow.reindex(sorted(topic_bow.columns), axis=1)\n",
    "\n",
    "#if there are values with none values (topic does not apply), then fill with 0's\n",
    "topic_bow.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of topic names to be columns for the new df\n",
    "TopicList = []\n",
    "TopicNum = lda_model_12.num_topics\n",
    "\n",
    "for i in range(0,TopicNum):\n",
    "    TopicList.append('Topic_' + str(i))\n",
    "    \n",
    "old_column_names = [i for i in range(14)]\n",
    "new_column_names = TopicList\n",
    "#rename each of the columns so that each column is called Table_X\n",
    "topic_bow.rename(columns=dict(zip(old_column_names, new_column_names)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_topics = pd.concat([data_clean, topic_bow], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_gender_subreddit = pd.DataFrame(comments_topics[\"Topic_0\"].groupby([comments_topics['gender'], comments_topics['subreddit']]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_gender_subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_column_names = [i for i in range(12)]\n",
    "new_column_names = [\"Thank you/appreciation\", \"Medical care\", \"Education/Family advice\", \"Furniture/Design\", \"Birth/Pregnancy\", \"Change/Potty training\", \"Physical appearance/Picture\", \"Work/Raise children\", \"Food\", \"Leisure activities\", \"School/Teaching\", \"Sleep training\"]\n",
    "\n",
    "for topic in comments_topics.iloc[:, 8:19]:\n",
    "    average = pd.DataFrame(comments_topics[topic].groupby([comments_topics['gender'], comments_topics['subreddit']]).mean())\n",
    "    topics_gender_subreddit = pd.concat([topics_gender_subreddit, average], axis=1, ignore_index = True)\n",
    "\n",
    "topics_gender_subreddit.rename(columns=dict(zip(old_column_names, new_column_names)), inplace=True)\n",
    "\n",
    "\n",
    "topics_gender_subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to excel the file with the score of each topic for each category\n",
    "topics_gender_subreddit.to_excel('table_topics_gender_subreddits.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_gender_subreddit = pd.read_excel('table_topics_gender_subreddits.xlsx', index_col = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = ['Fathers/Parenting', 'Fathers/Daddit', 'Mothers/Mommit', 'Mothers/Parenting']\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#create a heatmap\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "#X = A\n",
    "\n",
    "plt.pcolor(topics_gender_subreddit, norm=None, cmap='Blues')\n",
    "\n",
    "N, K = topics_gender_subreddit.shape\n",
    "\n",
    "#Topics = ['Sleep training', 'Breastfeeding','Potty training']\n",
    "#topic_labels = [k for k in Topics]\n",
    "\n",
    "# put the major ticks at the middle of each cell\n",
    "# the trailing semicolon ';' suppresses output\n",
    "plt.yticks(np.arange(topics_gender_subreddit.shape[0])+0.5, subreddits, rotation = 0, fontsize = 10);\n",
    "\n",
    "plt.xticks(np.arange(topics_gender_subreddit.shape[1])+0.5, new_column_names, rotation = 0, fontsize = 8.5);\n",
    "plt.ylabel('Subreddits', fontsize=20)\n",
    "plt.xlabel('LDA Topics', fontsize=20)\n",
    "\n",
    "# flip the y-axis so the texts are in the order we anticipate\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tick_params('x', length=10, width=2, which='major')\n",
    "\n",
    "# rotate the ticks on the x-axis\n",
    "plt.xticks()\n",
    "\n",
    "# add a legend\n",
    "plt.colorbar(cmap='Blues')\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()\n",
    "fig.set_size_inches(15, 15)\n",
    "#fig.savefig('RedditCompare.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of topics_gender_subreddit and add a column group with the names of each category\n",
    "plot_df = topics_gender_subreddit.copy()\n",
    "plot_df[\"group\"] = subreddits\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_2 = plt.figure(figsize=(5, 2))\n",
    "plt.scatter(x=np.arange(12), y=plot_df[plot_df[\"group\"] == \"Fathers/Parenting\"].values[0][:-1], label='Fathers/Parenting')\n",
    "plt.scatter(x=np.arange(12), y=plot_df[plot_df[\"group\"] == \"Fathers/Daddit\"].values[0][:-1], label=\"Fathers/Daddit\")\n",
    "plt.scatter(x=np.arange(12), y=plot_df[plot_df[\"group\"] == \"Mothers/Mommit\"].values[0][:-1], label=\"Mothers/Mommit\")\n",
    "plt.scatter(x=np.arange(12), y=plot_df[plot_df[\"group\"] == \"Mothers/Parenting\"].values[0][:-1], label=\"Mothers/Parenting\")\n",
    "\n",
    "\n",
    "plt.xticks(np.arange(topics_gender_subreddit.shape[1]), new_column_names, rotation = 0, fontsize = 9)\n",
    "plt.ylabel('Average score', fontsize=17)\n",
    "plt.xlabel('LDA Topics', fontsize=17)\n",
    "\n",
    "plt.tick_params('x', length=10, width=2, which='major')\n",
    "\n",
    "# rotate the ticks on the x-axis\n",
    "plt.xticks()\n",
    "plt.tight_layout() \n",
    "plt.legend(loc = \"best\")\n",
    "plt.grid()\n",
    "fig_2.set_size_inches(25, 25)\n",
    "plt.show()\n",
    "fig_2.savefig('score topics all authors.jpeg', bbox_inches='tight', dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = [\"Thank you/Appreciation\", \"Medical care\", \"Education/Family advice\", \"Furniture/Design\", \"Birth/Pregnancy\", \"Change/Potty training\", \"Physical appearance/Picture\", \"Work/Raise children\", \"Food\", \"Leisure activities\", \"School/Teaching\", \"Sleep training\"]\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('axes', axisbelow=True)\n",
    "\n",
    "fig_3 = plt.figure(figsize=(5, 2))\n",
    "plt.grid()\n",
    "plt.scatter(x=np.arange(12), y=plot_df[plot_df[\"group\"] == \"Fathers/Daddit\"].values[0][:-1], s=400,label=\"Fathers/Daddit\", c=\"orangered\")\n",
    "plt.scatter(x=np.arange(12), y=plot_df[plot_df[\"group\"] == \"Fathers/Parenting\"].values[0][:-1], s=400, label='Fathers/Parenting', c=\"pink\")\n",
    "plt.scatter(x=np.arange(12), y=plot_df[plot_df[\"group\"] == \"Mothers/Mommit\"].values[0][:-1], s=400,label=\"Mothers/Mommit\", c=\"royalblue\")\n",
    "plt.scatter(x=np.arange(12), y=plot_df[plot_df[\"group\"] == \"Mothers/Parenting\"].values[0][:-1], s=400,label=\"Mothers/Parenting\", c=\"skyblue\")\n",
    "\n",
    "\n",
    "plt.xticks(np.arange(plot_df.shape[1]-1), new_column_names, rotation = 40,  fontsize = 20, ha=\"right\")\n",
    "plt.yticks(fontsize = 20)\n",
    "\n",
    "plt.ylabel('Average score', fontsize=22)\n",
    "plt.xlabel('LDA Topics', fontsize=22)\n",
    "\n",
    "plt.tick_params('x', length=10, width=2, which='major')\n",
    "\n",
    "# rotate the ticks on the x-axis\n",
    "\n",
    "plt.xticks()\n",
    "plt.tight_layout() \n",
    "plt.legend(loc = \"best\", fontsize='large', ncol = 2)\n",
    "\n",
    "fig_3.set_size_inches(20, 10)\n",
    "plt.show()\n",
    "fig_3.savefig('comparison groups per topic.jpeg', bbox_inches='tight', dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_pergroup = plot_df.copy()\n",
    "plot_df_pergroup.reset_index(drop=True)\n",
    "plot_df_pergroup = plot_df_pergroup.set_index('group')\n",
    "plot_df_pergroup = plot_df_pergroup.T\n",
    "cols = [\"Fathers/Parenting\", \"Fathers/Daddit\", \"Mothers/Mommit\", \"Mothers/Parenting\"]\n",
    "#to have percentages, uncomment the comment bellow\n",
    "#perc_plot_df_pergroup[cols] = perc_plot_df_pergroup[cols].div(perc_plot_df_pergroup[cols].sum(axis=0), axis=1).multiply(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_4 = plt.figure(figsize=(5, 2))\n",
    "plt.scatter(x=np.arange(4), y=plot_df_pergroup.loc[\"Thank you/appreciation\",:].values, s=300, label='Thank you/appreciation')\n",
    "plt.plot(np.arange(4), plot_df_pergroup.loc[\"Thank you/appreciation\",:].values)\n",
    "plt.scatter(x=np.arange(4), y=plot_df_pergroup.loc[\"Medical care\",:].values, s=300, label='Medical care')\n",
    "plt.plot(np.arange(4), plot_df_pergroup.loc[\"Medical care\",:].values)\n",
    "plt.scatter(x=np.arange(4), y=plot_df_pergroup.loc[\"Education/Family advice\",:].values, s=300, label='Education/Family advice')\n",
    "plt.plot(np.arange(4), plot_df_pergroup.loc[\"Education/Family advice\",:].values)\n",
    "plt.scatter(x=np.arange(4), y=plot_df_pergroup.loc[\"Furniture/Design\",:].values, s=300, label='Furniture/Design')\n",
    "plt.plot(np.arange(4), plot_df_pergroup.loc[\"Furniture/Design\",:].values)\n",
    "plt.scatter(x=np.arange(4), y=plot_df_pergroup.loc[\"Birth/Pregnancy\",:].values, s=300, label='Birth/Pregnancy')\n",
    "plt.plot(np.arange(4), plot_df_pergroup.loc[\"Birth/Pregnancy\",:].values)\n",
    "plt.scatter(x=np.arange(4), y=plot_df_pergroup.loc[\"Change/Potty training\",:].values, s=300, label='Change/Potty training')\n",
    "plt.plot(np.arange(4), plot_df_pergroup.loc[\"Change/Potty training\",:].values)\n",
    "plt.scatter(x=np.arange(4), y=plot_df_pergroup.loc[\"Physical appearance/Picture\",:].values, s=300, label='Physical appearance/Picture')\n",
    "plt.plot(np.arange(4), plot_df_pergroup.loc[\"Physical appearance/Picture\"])\n",
    "plt.scatter(x=np.arange(4), y=plot_df_pergroup.loc[\"Work/Raise children\",:].values, s=300, label='Work/Raise children')\n",
    "plt.plot(np.arange(4), plot_df_pergroup.loc[\"Work/Raise children\",:].values)                                                 \n",
    "plt.scatter(x=np.arange(4), y=plot_df_pergroup.loc[\"Food\",:].values, s=300, label='Food')\n",
    "plt.plot(np.arange(4), plot_df_pergroup.loc[\"Food\",:].values)\n",
    "plt.scatter(x=np.arange(4), y=plot_df_pergroup.loc[\"Leisure activities\",:].values, s=300, label='Leisure activities')\n",
    "plt.plot(np.arange(4), plot_df_pergroup.loc[\"Leisure activities\",:].values)\n",
    "plt.scatter(x=np.arange(4), y=plot_df_pergroup.loc[\"School/Teaching\",:].values, s=300, label='School/Teaching')\n",
    "plt.plot(np.arange(4), plot_df_pergroup.loc[\"School/Teaching\",:].values)\n",
    "plt.scatter(x=np.arange(4), y=plot_df_pergroup.loc[\"Sleep training\",:].values, s=300, label='Sleep training')\n",
    "plt.plot(np.arange(4), plot_df_pergroup.loc[\"Sleep training\",:].values)\n",
    "\n",
    "\n",
    "plt.xticks(np.arange(topics_gender_subreddit.shape[0]), cols, rotation = 0, fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.ylabel('Average score', fontsize=22)\n",
    "plt.xlabel('Categories', fontsize=22)\n",
    "\n",
    "plt.tick_params('x', length=10, width=2, which='major')\n",
    "\n",
    "# rotate the ticks on the x-axis\n",
    "plt.xticks()\n",
    "plt.tight_layout() \n",
    "plt.legend(loc=\"upper right\", ncol=2, fontsize='large')\n",
    "plt.grid()\n",
    "fig_4.set_size_inches(20, 30)\n",
    "plt.show()\n",
    "fig_4.savefig('topics per group.jpeg', bbox_inches='tight', dpi=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most representative comments for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic 0\n",
    "comments_topics[comments_topics[\"Topic_0\"]>0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic 1\n",
    "comments_topics[comments_topics[\"Topic_1\"]>0.994]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic 2\n",
    "comments_topics.body[comments_topics[\"Topic_2\"]>0.995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic 3\n",
    "comments_topics.body[comments_topics[\"Topic_3\"]>0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Topic 4\n",
    "comments_topics[comments_topics[\"Topic_4\"]>0.98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic 5\n",
    "comments_topics[comments_topics[\"Topic_5\"]>0.98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic 6\n",
    "comments_topics[comments_topics[\"Topic_6\"]>0.983]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic 7\n",
    "comments_topics[comments_topics[\"Topic_7\"]>0.987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic 8\n",
    "comments_topics[comments_topics[\"Topic_8\"]>0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic 9\n",
    "comments_topics[comments_topics[\"Topic_9\"]>0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic 10\n",
    "comments_topics[comments_topics[\"Topic_10\"]>0.992]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic 11\n",
    "comments_topics[comments_topics[\"Topic_11\"]>0.994]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "reddit-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "master_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
